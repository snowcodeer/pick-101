# DrQ-v2 Image-Based RL for SO-101 Lift Task
# Stage 3 curriculum: gripper near cube, needs to grasp and lift
# v15: adds penalty for keeping gripper open too long

experiment_name: image_rl

# Environment settings
env:
  env_name: so101_lift
  episode_length: 200
  image_size: 84
  curriculum_stage: 3  # 0=normal, 1=lifted, 2=table grasp, 3=near cube, 4=far
  reward_version: v15
  lock_wrist: false
  stddev_schedule: "linear(1.0,0.1,500000)"

# Pixel-based training
pixels: true
frame_stack: 3
num_train_envs: 8
batch_size: 256

# Training settings
num_train_frames: 2000000
eval_every_steps: 10000
num_eval_episodes: 10
replay_size_before_train: 2000
action_repeat: 2
seed: 1

# Checkpointing
save_snapshot: true
snapshot_every_n: 6250  # ~50k steps with 8 envs

# Replay buffer
replay:
  size: 100000
  prioritization: false

# DrQ-v2 method overrides (smaller network for faster iteration)
method:
  encoder_model:
    channels: 32
  critic_model:
    mlp_nodes: [256, 256]
  actor_model:
    mlp_nodes: [256, 256]

# Logging
log_eval_video_every: 100000  # Save eval video + debug log every 100k steps

wandb:
  use: false
  entity: gando
  project: so101-image-rl
  name: drqv2_lift_s3_v15

tb:
  use: true
  log_dir: ./runs/image_rl/tb_logs
  name: drqv2_lift_s3_v15
